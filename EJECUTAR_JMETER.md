# ðŸŽ¯ GuÃ­a de EjecuciÃ³n del Test Plan en JMeter

## ðŸ“‹ Test Plan Completo - Sistema de GestiÃ³n de Alumnos

Este archivo `test_plan.jmx` cumple con **TODOS** los requisitos del documento del proyecto.

---

## âœ… Requisitos Cumplidos

### 1. Thread Groups (Grupos de Usuarios) âœ“
- âœ… **Test 1**: 10 usuarios - AutenticaciÃ³n
- âœ… **Test 2**: 50 usuarios - AutenticaciÃ³n (carga media)
- âœ… **Test 3**: 50 usuarios - Registro masivo con CSV
- âœ… **Test 4**: 100 usuarios - Consulta pesada con JOIN
- âœ… **Test 5**: 100 usuarios - CÃ¡lculo en memoria (CPU)
- âœ… **Test 6**: 200 usuarios - Prueba de estrÃ©s (opcional, deshabilitado por defecto)

### 2. Elementos Obligatorios del Test Plan âœ“
- âœ… **HTTP Request**: Todos los tests usan HTTP Sampler
- âœ… **CSV Data Set Config**: Test 3 usa `alumnos_test.csv`
- âœ… **Timers**: 
  - Constant Timer (100-200ms)
  - Gaussian Random Timer (300ms Â±100ms, 500ms Â±200ms)
- âœ… **Assertions**:
  - Response Assertion (cÃ³digos 200, 201)
  - JSON Path Assertion (validar success: true)
  - Duration Assertion (tiempos mÃ¡ximos)

### 3. Listeners Incluidos âœ“
- âœ… **Summary Report** â†’ `resultados/summary_report.csv`
- âœ… **Aggregate Report** â†’ `resultados/aggregate_report.csv`
- âœ… **View Results in Table** â†’ `resultados/table_results.csv`
- âœ… **Graph Results** â†’ `resultados/graph_results.csv`
- âœ… **Response Time Graph** â†’ `resultados/response_time.csv`
- âœ… **View Results Tree** (para debugging)

### 4. Validaciones MÃ­nimas âœ“
- âœ… Tiempos mÃ¡ximos de respuesta (Duration Assertion)
- âœ… Cantidad de errores (% Error en Reports)
- âœ… Throughput (peticiones por segundo)
- âœ… Latencia (en todos los reports)
- âœ… Tiempo promedio por request
- âœ… Percentiles 90%, 95%, 99% (en Aggregate Report)

---

## ðŸš€ CÃ³mo Ejecutar el Test Plan

### OpciÃ³n 1: Modo GUI (Para anÃ¡lisis y debugging)

```bash
# 1. Ir a la carpeta del proyecto
cd /Users/dru/Documents/Repositories/flask-alumno

# 2. Asegurarse de que el servidor Flask estÃ© corriendo
source venv/bin/activate
python run.py

# 3. En otra terminal, abrir JMeter
jmeter

# 4. En JMeter:
#    - File â†’ Open
#    - Seleccionar: test_plan.jmx
#    - Click en el botÃ³n verde "Start" (â–¶)
```

### OpciÃ³n 2: Modo CLI (Para resultados finales)

```bash
# Ejecutar test plan completo en modo CLI
jmeter -n -t test_plan.jmx -l resultados/resultados_completos.jtl -e -o resultados/reporte_html

# ParÃ¡metros:
# -n: Modo no-GUI
# -t: Archivo del test plan
# -l: Archivo de log de resultados
# -e: Generar reporte HTML al final
# -o: Carpeta para el reporte HTML
```

### OpciÃ³n 3: Ejecutar Tests Individuales

```bash
# Solo Test 1 (10 usuarios - AutenticaciÃ³n)
jmeter -n -t test_plan.jmx -l resultados/test1.jtl -Jtest=1

# Solo Test 3 (50 usuarios - Registro CSV)
jmeter -n -t test_plan.jmx -l resultados/test3.jtl -Jtest=3

# Solo Test 4 (100 usuarios - Consulta pesada)
jmeter -n -t test_plan.jmx -l resultados/test4.jtl -Jtest=4
```

---

## ðŸ“Š Estructura del Test Plan

```
test_plan.jmx
â”œâ”€â”€ Variables Globales
â”‚   â”œâ”€â”€ SERVER = localhost
â”‚   â”œâ”€â”€ PORT = 5001
â”‚   â””â”€â”€ PROTOCOL = http
â”‚
â”œâ”€â”€ HTTP Request Defaults
â”‚   â””â”€â”€ ConfiguraciÃ³n comÃºn para todos los requests
â”‚
â”œâ”€â”€ HTTP Header Manager
â”‚   â””â”€â”€ Content-Type: application/json
â”‚
â”œâ”€â”€ Test 1: AutenticaciÃ³n (10 usuarios)
â”‚   â”œâ”€â”€ Gaussian Random Timer (300ms Â±100ms)
â”‚   â”œâ”€â”€ POST /api/login
â”‚   â”œâ”€â”€ JSON Extractor (token)
â”‚   â”œâ”€â”€ Response Assertion (200 OK)
â”‚   â”œâ”€â”€ JSON Assertion (success: true)
â”‚   â””â”€â”€ Duration Assertion (< 1000ms)
â”‚
â”œâ”€â”€ Test 2: AutenticaciÃ³n (50 usuarios)
â”‚   â”œâ”€â”€ Gaussian Random Timer (300ms Â±100ms)
â”‚   â”œâ”€â”€ POST /api/login
â”‚   â”œâ”€â”€ JSON Extractor (token)
â”‚   â”œâ”€â”€ Response Assertion (200 OK)
â”‚   â””â”€â”€ Duration Assertion (< 1500ms)
â”‚
â”œâ”€â”€ Test 3: Registro Masivo CSV (50 usuarios)
â”‚   â”œâ”€â”€ CSV Data Set Config (alumnos_test.csv)
â”‚   â”œâ”€â”€ Constant Timer (200ms)
â”‚   â”œâ”€â”€ POST /api/login â†’ obtener token
â”‚   â”œâ”€â”€ POST /api/alumno/registrar (con datos CSV)
â”‚   â”œâ”€â”€ Response Assertion (201 Created)
â”‚   â””â”€â”€ Duration Assertion (< 2000ms)
â”‚
â”œâ”€â”€ Test 4: Consulta Pesada JOIN (100 usuarios)
â”‚   â”œâ”€â”€ Gaussian Random Timer (500ms Â±200ms)
â”‚   â”œâ”€â”€ POST /api/login â†’ obtener token
â”‚   â”œâ”€â”€ GET /api/cursos/estadisticas (JOIN de 3 tablas)
â”‚   â”œâ”€â”€ Response Assertion (200 OK)
â”‚   â””â”€â”€ Duration Assertion (< 3000ms)
â”‚
â”œâ”€â”€ Test 5: CÃ¡lculo en Memoria (100 usuarios)
â”‚   â”œâ”€â”€ Constant Timer (100ms)
â”‚   â”œâ”€â”€ POST /api/login â†’ obtener token
â”‚   â”œâ”€â”€ POST /api/simular-promedio (CPU intensive)
â”‚   â”œâ”€â”€ Response Assertion (200 OK)
â”‚   â”œâ”€â”€ JSON Assertion (success: true)
â”‚   â””â”€â”€ Duration Assertion (< 500ms)
â”‚
â”œâ”€â”€ Test 6: EstrÃ©s (200 usuarios) [DESHABILITADO]
â”‚   â”œâ”€â”€ Gaussian Random Timer (800ms Â±300ms)
â”‚   â”œâ”€â”€ POST /api/login
â”‚   â”œâ”€â”€ GET /api/cursos/estadisticas
â”‚   â””â”€â”€ Response Assertion (200 OK)
â”‚
â””â”€â”€ Listeners (Reportes)
    â”œâ”€â”€ Summary Report
    â”œâ”€â”€ Aggregate Report
    â”œâ”€â”€ View Results in Table
    â”œâ”€â”€ Graph Results
    â”œâ”€â”€ Response Time Graph
    â””â”€â”€ View Results Tree
```

---

## ðŸ“ˆ MÃ©tricas que se Capturan

### En todos los reports se incluyen:

1. **Tiempo de Respuesta**
   - Average (promedio)
   - Min / Max
   - Median

2. **Percentiles**
   - 90% Line (Percentil 90)
   - 95% Line (Percentil 95)
   - 99% Line (Percentil 99)

3. **Throughput**
   - Requests/segundo
   - KB/segundo

4. **Latencia**
   - Tiempo hasta el primer byte
   - Connect Time

5. **Errores**
   - Error % (porcentaje)
   - Cantidad total de errores
   - Tipo de error

6. **Datos Transferidos**
   - Bytes enviados
   - Bytes recibidos

---

## ðŸŽ¯ Escenarios de Prueba

### Escenario 1: Carga Ligera (Test 1)
**Objetivo**: Baseline de rendimiento
- **Usuarios**: 10 concurrentes
- **DuraciÃ³n**: ~2.5 minutos (50 loops)
- **Endpoint**: POST /api/login
- **MÃ©trica clave**: Response Time < 1000ms

### Escenario 2: Carga Media (Test 2)
**Objetivo**: Comportamiento bajo carga normal
- **Usuarios**: 50 concurrentes
- **DuraciÃ³n**: ~2.5 minutos (30 loops)
- **Endpoint**: POST /api/login
- **MÃ©trica clave**: Response Time < 1500ms

### Escenario 3: Escritura Masiva (Test 3)
**Objetivo**: Evaluar INSERT masivo en BD
- **Usuarios**: 50 concurrentes
- **DuraciÃ³n**: ~10 segundos (1 loop con CSV)
- **Endpoint**: POST /api/alumno/registrar
- **MÃ©trica clave**: Response Time < 2000ms, Error % < 5%
- **Datos**: CSV con 50 alumnos Ãºnicos

### Escenario 4: Lectura Compleja (Test 4)
**Objetivo**: Evaluar consultas con JOIN
- **Usuarios**: 100 concurrentes
- **DuraciÃ³n**: ~3.5 minutos (20 loops)
- **Endpoint**: GET /api/cursos/estadisticas
- **MÃ©trica clave**: Response Time < 3000ms, Latency

### Escenario 5: CPU Intensivo (Test 5)
**Objetivo**: Evaluar procesamiento sin I/O
- **Usuarios**: 100 concurrentes
- **DuraciÃ³n**: ~5 minutos (50 loops)
- **Endpoint**: POST /api/simular-promedio
- **MÃ©trica clave**: Response Time < 500ms, Throughput alto

### Escenario 6: EstrÃ©s (Test 6) [OPCIONAL]
**Objetivo**: Encontrar el punto de quiebre
- **Usuarios**: 200 concurrentes
- **DuraciÃ³n**: ~2 minutos (10 loops)
- **Endpoint**: GET /api/cursos/estadisticas
- **MÃ©trica clave**: Error %, punto de saturaciÃ³n

---

## ðŸ”§ ConfiguraciÃ³n del Test Plan

### Variables que puedes cambiar:

En el Test Plan â†’ Variables definidas:
```
SERVER = localhost      (cambiar si estÃ¡ en otro host)
PORT = 5001            (cambiar segÃºn tu configuraciÃ³n)
PROTOCOL = http        (cambiar a https si aplica)
```

### Archivo CSV:

El Test 3 usa: `data/alumnos_test.csv`

**Importante**: 
- La ruta es relativa al directorio donde ejecutas JMeter
- Si ejecutas desde otra carpeta, ajusta la ruta en CSV Data Set Config
- O usa ruta absoluta: `/Users/dru/Documents/Repositories/flask-alumno/data/alumnos_test.csv`

---

## âš ï¸ Antes de Ejecutar

### Checklist:

- [ ] **Servidor Flask corriendo** en puerto 5001
  ```bash
  source venv/bin/activate
  python run.py
  ```

- [ ] **MySQL corriendo**
  ```bash
  mysql.server status
  ```

- [ ] **Carpeta resultados** creada (ya existe)

- [ ] **Archivo CSV** disponible en `data/alumnos_test.csv` âœ“

- [ ] **JMeter instalado**
  ```bash
  jmeter -v
  # DeberÃ­a mostrar: Apache JMeter 5.x
  ```

- [ ] **Limpiar datos anteriores** (opcional)
  ```bash
  bash scripts_utils.sh clean-alumnos
  ```

---

## ðŸ“Š Generar Reporte HTML Profesional

DespuÃ©s de ejecutar el test:

```bash
# 1. Ejecutar el test guardando resultados
jmeter -n -t test_plan.jmx -l resultados/resultados.jtl

# 2. Generar reporte HTML desde el .jtl
jmeter -g resultados/resultados.jtl -o resultados/reporte_html

# 3. Abrir el reporte
open resultados/reporte_html/index.html
```

El reporte HTML incluye:
- Dashboard con grÃ¡ficos interactivos
- EstadÃ­sticas detalladas
- Top 5 requests mÃ¡s lentos
- DistribuciÃ³n de errores
- GrÃ¡ficos de Response Time Over Time
- Throughput Over Time
- Active Threads Over Time

---

## ðŸ“ Para tu Informe TÃ©cnico

### Datos que debes incluir:

1. **ConfiguraciÃ³n de Pruebas**
   - NÃºmero de usuarios por test
   - Ramp-up time
   - Loops
   - DuraciÃ³n total

2. **MÃ©tricas Obtenidas** (de Aggregate Report)
   - Average Response Time
   - 90th, 95th, 99th Percentile
   - Throughput (req/s)
   - Error %
   - Latency

3. **AnÃ¡lisis por Test**
   - Test 1 (10 usuarios): Baseline
   - Test 2 (50 usuarios): Carga media
   - Test 3 (CSV): Escritura masiva
   - Test 4 (100 usuarios): Lectura compleja
   - Test 5 (CPU): Procesamiento intensivo

4. **Conclusiones**
   - Endpoint mÃ¡s lento
   - Endpoint con mÃ¡s errores
   - Capacidad mÃ¡xima del servidor
   - Cuellos de botella identificados

5. **Recomendaciones**
   - Optimizaciones de BD (Ã­ndices, queries)
   - Escalamiento horizontal/vertical
   - Caching
   - Connection pooling

---

## ðŸŽ“ Tips para el Informe

### Screenshots que debes tomar:

1. **Aggregate Report** con todos los tests
2. **Response Time Graph** mostrando picos
3. **Summary Report** con totales
4. **View Results Tree** mostrando requests exitosos
5. **Reporte HTML** - Dashboard principal

### GrÃ¡ficos para incluir:

- Response Time vs NÃºmero de Usuarios
- Throughput vs NÃºmero de Usuarios
- Error % por cada test
- Latency vs Response Time

---

## âœ… Validaciones AutomÃ¡ticas

El Test Plan incluye validaciones que fallarÃ¡n automÃ¡ticamente si:

- âŒ Response Code no es 200 o 201
- âŒ JSON no contiene `"success": true`
- âŒ Response Time excede el mÃ¡ximo configurado
- âŒ Token no se extrae correctamente

Estos errores se verÃ¡n en rojo en el reporte.

---

## ðŸš€ Â¡Listo para Ejecutar!

Tu Test Plan estÃ¡ **100% completo** y cumple con **todos** los requisitos del documento del proyecto.

### Comando rÃ¡pido para empezar:

```bash
# Abrir JMeter con el Test Plan
jmeter -t test_plan.jmx
```

**Â¡Buena suerte con tu proyecto!** ðŸŽ¯
